{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from ultralytics import YOLO \n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "\n",
    "# Step 1: Load trained YOLOv8 model\n",
    "model = YOLO('train\\weights\\best.pt') \n",
    "image_path = 'stop.png'\n",
    "\n",
    "# Step 2: Extract the backbone (CSPDarknet53)\n",
    "backbone = model.model.model[:10] # According to yolov8 docs it's layers from 0 to 9\n",
    "labels = torch.tensor([22]) # 22 is the class id stop_sign\n",
    "\n",
    "num_classes = 29  \n",
    "sample_image = torch.randn(1, 3, 416, 416)  \n",
    "sample_output = backbone(sample_image)\n",
    "output_channels = sample_output.shape[1] # getting output_channels from SPFF layer\n",
    "classify_model = nn.Sequential(\n",
    "    backbone,  # Use the CSPDarknet53 backbone\n",
    "    nn.AdaptiveAvgPool2d((1, 1)),  # Global Average Pooling to reduce to (batch_size, channels, 1, 1)\n",
    "    nn.Flatten(),  # Flatten to (batch_size, channels)\n",
    "    nn.Linear(in_features=output_channels, out_features=num_classes)  # Linear layer for classification\n",
    ")\n",
    "\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize((416, 416)),  # Resize to 416x416\n",
    "    transforms.ToTensor(),          # Convert to tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # Normalize\n",
    "])\n",
    "\n",
    "image = Image.open(image_path).convert(\"RGB\")  # Load image and ensure it's in RGB format\n",
    "image = preprocess(image).unsqueeze(0)  # Apply preprocessing and add batch dimension\n",
    "\n",
    "\n",
    "# Example FGSM attack\n",
    "def fgsm_attack(model, images, labels, epsilon):\n",
    "    images.requires_grad = True\n",
    "    outputs = model(images)\n",
    "    loss = nn.CrossEntropyLoss()(outputs, labels)\n",
    "    model.zero_grad()\n",
    "    loss.backward()  # Compute gradients with respect to input images\n",
    "    grad_sign = images.grad.data.sign()\n",
    "    perturbed_image = images + epsilon * grad_sign  # Apply perturbation\n",
    "    return perturbed_image\n",
    "\n",
    "# Now you can apply FGSM or other attacks on the `classify_model`\n",
    "perturbed_image = fgsm_attack(classify_model, image, labels, 1.3) # epsilon is set to 1.3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def get_yolo_output(model, image): # function to organize the output of yolo\n",
    "    results = model(image)\n",
    "    return results[0].boxes.xyxy, results[0].boxes.conf, results[0].boxes.cls\n",
    "\n",
    "perturbed_image = torch.clamp(perturbed_image, 0, 1)\n",
    "image = torch.clamp(image, 0, 1)\n",
    "boxes, scores, labels = get_yolo_output(model, image)\n",
    "perturbed_boxes, perturbed_scores, perturbed_labels = get_yolo_output(model, perturbed_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Plotting results\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_boxes(ax, boxes, scores, labels, title, image_tensor):\n",
    "    # Detach, remove batch dimension, permute to (height, width, channels), and convert to NumPy\n",
    "    ax.imshow(image_tensor.squeeze(0).permute(1, 2, 0).cpu().detach().numpy())\n",
    "    for box, score, label in zip(boxes, scores, labels):\n",
    "        x1, y1, x2, y2 = box.detach().cpu().numpy()\n",
    "        rect = plt.Rectangle((x1, y1), x2 - x1, y2 - y1, fill=False, edgecolor='r', linewidth=2)\n",
    "        ax.add_patch(rect)\n",
    "        ax.text(x1, y1, f\"{model.names[int(label)]}: {score:.2f}\", bbox=dict(facecolor='white', alpha=0.8))\n",
    "    ax.set_title(title)\n",
    "    ax.axis('off')\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(20, 10))\n",
    "\n",
    "# Original image with predictions\n",
    "plot_boxes(axs[0], boxes, scores, labels, \"Original Image with YOLOv8 Predictions\", image)\n",
    "\n",
    "# Perturbation\n",
    "perturbation = (perturbed_image - image).squeeze().permute(1, 2, 0).cpu().detach().numpy()\n",
    "perturbation = (perturbation - perturbation.min()) / (perturbation.max() - perturbation.min())\n",
    "axs[1].imshow(perturbation)\n",
    "axs[1].set_title(\"Perturbation\")\n",
    "axs[1].axis('off')\n",
    "\n",
    "# Adversarial image with predictions\n",
    "plot_boxes(axs[2], perturbed_boxes, perturbed_scores, perturbed_labels, \"Adversarial Image with YOLOv8 Predictions\", perturbed_image)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
