{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/seba20-0/Adversarial-Attacks-on-YOLO.git"
      ],
      "metadata": {
        "id": "0Hz1bA0AOSEX"
      },
      "id": "0Hz1bA0AOSEX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd Adversarial-Attacks-on-YOLO/"
      ],
      "metadata": {
        "id": "urm60YRQOdo1"
      },
      "id": "urm60YRQOdo1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "118d53bc",
      "metadata": {
        "id": "118d53bc"
      },
      "source": [
        "# Adversarial Attacks on Pretrained Vision Models\n",
        "\n",
        "In this notebook, I will demonstrate how to perform adversarial attacks on a pretrained vision model without retraining it. The workflow will be as follows:\n",
        "\n",
        "1. **Model Selection**: Load a pretrained vision model (e.g., ResNet, VGG) from a popular library such as PyTorch or TensorFlow.\n",
        "2. **Dataset**: Use images from the ImageNet dataset, focusing on a specific class for targeted attacks.\n",
        "3. **Prediction**: Pass the selected images through the model to obtain baseline predictions.\n",
        "4. **Adversarial Attack**: Apply an adversarial attack method (e.g., FGSM, PGD) to the images of the chosen class.\n",
        "5. **Evaluation**: Compare the model's predictions on clean vs. adversarial images to assess the effectiveness of the attack.\n",
        "\n",
        "No model training will be performed; the focus is solely on testing and attacking the pretrained model using ImageNet class images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5a98e9e",
      "metadata": {
        "id": "a5a98e9e"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models\n",
        "\n",
        "# Load pretrained VGG16 model\n",
        "\n",
        "# Set model to evaluation mode\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a455451e",
      "metadata": {
        "id": "a455451e"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "import json\n",
        "import requests\n",
        "\n",
        "# Load and preprocess the image\n",
        "img_path = ''\n",
        "image = Image.open(img_path).convert('RGB')\n",
        "\n",
        "\n",
        "# transform the image resize, centercrop, ToTensor, and normalize using imagenet mean and std\n",
        "preprocess = _\n",
        "\n",
        "\n",
        "# preprocess and add batch dimension\n",
        "input_tensor = _\n",
        "\n",
        "# Inference\n",
        "with torch.no_grad():\n",
        "    output = model(input_tensor)\n",
        "    _, predicted = output.max(1)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download ImageNet class labels\n",
        "LABELS_URL = 'https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt'\n",
        "labels = requests.get(LABELS_URL).text.splitlines()"
      ],
      "metadata": {
        "id": "8bl7xxZWurq4"
      },
      "id": "8bl7xxZWurq4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "901e7d2b",
      "metadata": {
        "id": "901e7d2b"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Display the image\n",
        "plt.imshow(image)\n",
        "plt.axis('off')\n",
        "plt.title('Input Image')\n",
        "plt.show()\n",
        "\n",
        "# Print predicted class\n",
        "print('Predicted class:', labels[predicted.item()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "29965c50",
      "metadata": {
        "id": "29965c50"
      },
      "outputs": [],
      "source": [
        "# Get top 5 predictions and their probabilities\n",
        "with torch.no_grad():\n",
        "    probs = _\n",
        "    top5_probs, top5_indices = _\n",
        "\n",
        "# Display top 5 predicted classes and probabilities\n",
        "for i in range(5):\n",
        "    idx = top5_indices[0, i].item()\n",
        "    prob = top5_probs[0, i].item()\n",
        "    print(f\"{i+1}. {labels[idx]} ({prob:.4f})\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "66a327a3",
      "metadata": {
        "id": "66a327a3"
      },
      "source": [
        "## FGSM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e08cb16b",
      "metadata": {
        "id": "e08cb16b"
      },
      "outputs": [],
      "source": [
        "from attacks.fgsm import FGSM\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Prepare label for untargeted attack (use predicted label)\n",
        "label_tensor = _\n",
        "\n",
        "# Instantiate FGSM\n",
        "epsilon = 0.4\n",
        "fgsm = _\n",
        "\n",
        "# Generate adversarial example\n",
        "adv_image = fgsm.attack(_)\n",
        "\n",
        "# Display adversarial image\n",
        "adv_img_np = adv_image.squeeze().detach().cpu().numpy().transpose(1,2,0)\n",
        "adv_img_np = adv_img_np * [0.229, 0.224, 0.225] + [0.485, 0.456, 0.406]  # Unnormalize\n",
        "adv_img_np = adv_img_np.clip(0, 1)\n",
        "\n",
        "# Calculate perturbation\n",
        "perturbation = (adv_image - input_tensor).squeeze().detach().cpu().numpy().transpose(1,2,0)\n",
        "perturbation = perturbation * [0.229, 0.224, 0.225]  # Unnormalize (no mean added for noise)\n",
        "perturbation = perturbation.clip(-0.5, 0.5)  # Clip for visualization\n",
        "\n",
        "# Show original image\n",
        "orig_img_np = input_tensor.squeeze().detach().cpu().numpy().transpose(1,2,0)\n",
        "orig_img_np = orig_img_np * [0.229, 0.224, 0.225] + [0.485, 0.456, 0.406]\n",
        "orig_img_np = orig_img_np.clip(0, 1)\n",
        "\n",
        "fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
        "axs[0].imshow(orig_img_np)\n",
        "axs[0].set_title('Original Image')\n",
        "axs[0].axis('off')\n",
        "\n",
        "axs[1].imshow(perturbation, cmap='seismic')\n",
        "axs[1].set_title('Perturbation (Noise)')\n",
        "axs[1].axis('off')\n",
        "\n",
        "axs[2].imshow(adv_img_np)\n",
        "axs[2].set_title('Adversarial Image')\n",
        "axs[2].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a00742a1",
      "metadata": {
        "id": "a00742a1"
      },
      "outputs": [],
      "source": [
        "# Predict the label of the adversarial image\n",
        "with torch.no_grad():\n",
        "  # get the model output on adv_image\n",
        "    adv_output = _\n",
        "    #extract the predicted clas\n",
        "    _, adv_predicted = adv_output.max(1)\n",
        "\n",
        "# Show adversarial image with predicted label\n",
        "plt.imshow(adv_img_np)\n",
        "plt.axis('off')\n",
        "plt.title(f'Adversarial Image\\nPredicted: {labels[adv_predicted.item()]}')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed946d4b",
      "metadata": {
        "id": "ed946d4b"
      },
      "outputs": [],
      "source": [
        "# Find the ImageNet class index for 'balloon '\n",
        "target_class_name = 'balloon'\n",
        "target_class_idx = labels.index(target_class_name)  # Get index for balloon\n",
        "target_label_tensor = torch.tensor([target_class_idx])\n",
        "\n",
        "# Instantiate FGSM for targeted attack\n",
        "epsilon = 0.1\n",
        "\n",
        "# instantiate fgsm with targeted as True\n",
        "fgsm_targeted = _\n",
        "\n",
        "# Generate targeted adversarial example from target_label_tensor\n",
        "adv_image_targeted = _\n",
        "\n",
        "# Display targeted adversarial image\n",
        "adv_img_targeted_np = adv_image_targeted.squeeze().detach().cpu().numpy().transpose(1,2,0)\n",
        "adv_img_targeted_np = adv_img_targeted_np * [0.229, 0.224, 0.225] + [0.485, 0.456, 0.406]  # Unnormalize\n",
        "adv_img_targeted_np = adv_img_targeted_np.clip(0, 1)\n",
        "\n",
        "plt.imshow(adv_img_targeted_np)\n",
        "plt.axis('off')\n",
        "plt.title('Targeted Adversarial Image (balloon )')\n",
        "plt.show()\n",
        "\n",
        "# Predict the label of the targeted adversarial image\n",
        "with torch.no_grad():\n",
        "    adv_output_targeted = model(adv_image_targeted)\n",
        "    _, adv_predicted_targeted = adv_output_targeted.max(1)\n",
        "\n",
        "print(f\"Predicted class for targeted attack: {labels[adv_predicted_targeted.item()]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e13e3948",
      "metadata": {
        "id": "e13e3948"
      },
      "source": [
        "## BIM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f08a3d1b",
      "metadata": {
        "id": "f08a3d1b"
      },
      "outputs": [],
      "source": [
        "# Targeted BIM attack to force prediction as 'balloon'\n",
        "from attacks.bim import BIM\n",
        "\n",
        "# BIM parameters\n",
        "epsilon = 0.1\n",
        "alpha = 0.1\n",
        "num_iterations = 60\n",
        "targeted = True\n",
        "\n",
        "\n",
        "# Instantiate BIM for targeted attack\n",
        "bim_targeted = _\n",
        "\n",
        "# Generate targeted adversarial example using target_label_tensor\n",
        "adv_image_bim = _\n",
        "\n",
        "# Display targeted adversarial image\n",
        "adv_img_bim_np = adv_image_bim.squeeze().detach().cpu().numpy().transpose(1,2,0)\n",
        "adv_img_bim_np = adv_img_bim_np * [0.229, 0.224, 0.225] + [0.485, 0.456, 0.406]  # Unnormalize\n",
        "adv_img_bim_np = adv_img_bim_np.clip(0, 1)\n",
        "# Show original image, perturbation, and BIM adversarial image side by side\n",
        "perturbation_bim = (adv_image_bim - input_tensor).squeeze().detach().cpu().numpy().transpose(1,2,0)\n",
        "perturbation_bim = perturbation_bim * [0.229, 0.224, 0.225]  # Unnormalize (no mean added for noise)\n",
        "perturbation_bim = perturbation_bim.clip(-0.5, 0.5)  # Clip for visualization\n",
        "\n",
        "fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
        "axs[0].imshow(orig_img_np)\n",
        "axs[0].set_title('Original Image')\n",
        "axs[0].axis('off')\n",
        "\n",
        "axs[1].imshow(perturbation_bim, cmap='seismic')\n",
        "axs[1].set_title('Perturbation (Noise)')\n",
        "axs[1].axis('off')\n",
        "\n",
        "axs[2].imshow(adv_img_bim_np)\n",
        "axs[2].set_title('BIM Adversarial Image')\n",
        "axs[2].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Predict the label of the BIM adversarial image\n",
        "with torch.no_grad():\n",
        "    adv_output_bim = model(adv_image_bim)\n",
        "    _, adv_predicted_bim = adv_output_bim.max(1)\n",
        "\n",
        "print(f\"Predicted class for BIM targeted attack: {labels[adv_predicted_bim.item()]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6808681",
      "metadata": {
        "id": "d6808681"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}